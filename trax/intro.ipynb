{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7yuytuIllsv1"
      },
      "source": [
        "# Trax Quick Intro\n",
        "\n",
        "We train **Trax Transformer** on a simple copy problem and run inference.\n",
        "* Training and inference can run on TPU, even with multiple input lengths\n",
        "* Inputs are fed from python but it's asynchronous so doesn't slow training\n",
        "* Transformer in predict mode implements fast inference (attention caches)\n",
        "\n",
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BIl27504La0G"
      },
      "source": [
        "## General Setup\n",
        "Execute the following few cells (once) before running any of the code samples in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "both",
        "colab": {},
        "colab_type": "code",
        "id": "oILRLCWN_16u"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Copyright 2020 Google LLC.\n",
        "\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as onp  # np used below for trax.backend.numpy\n",
        "\n",
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "both",
        "colab": {},
        "colab_type": "code",
        "id": "vlGjGoGMTt-D"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Import Trax\n",
        "\n",
        "! pip install -q -U trax\n",
        "! pip install -q tensorflow\n",
        "\n",
        "import trax\n",
        "from trax.math import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-LQ89rFFsEdk"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "height": 68
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 296,
          "status": "ok",
          "timestamp": 1578613890546,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "djTiSLcaNFGa",
        "outputId": "4c7a6a62-3561-4c66-e99e-69f4bf0bdfb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs[0]:  [ 0 11 13 12 24  9 16 14 18 30  0 11 13 12 24  9 16 14 18 30]\n",
            "Targets[0]: [ 0 11 13 12 24  9 16 14 18 30  0 11 13 12 24  9 16 14 18 30]\n",
            "Mask[0]:    [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "# Construct inputs, see one batch\n",
        "def copy_inputs(n_devices):\n",
        "   return trax.supervised.inputs.sequence_copy_inputs(\n",
        "       n_devices, vocab_size=32, batch_size=8,\n",
        "       train_lengths=[10, 20], eval_lengths=[10, 20])\n",
        "data_stream = copy_inputs(1).train_stream()\n",
        "inputs, targets, mask = next(data_stream)\n",
        "print(\"Inputs[0]:  %s\" % str(inputs[0]))\n",
        "print(\"Targets[0]: %s\" % str(targets[0]))\n",
        "print(\"Mask[0]:    %s\" % str(mask[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 11415,
          "status": "ok",
          "timestamp": 1578613901980,
          "user": {
            "displayName": "Lukasz Kaiser",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC8pChl87HbK_eOtVhtNPwUVx8btvfyYzH9UHn3=s64",
            "userId": "13267693649565518272"
          },
          "user_tz": 480
        },
        "id": "bYWNWL9MJHv9",
        "outputId": "1347ac0e-05e7-42c0-8fa7-701f3dbe56e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8, 20, 256) (8, 20) (8, 20)\n"
          ]
        }
      ],
      "source": [
        "# Transformer LM\n",
        "def transformer_lm(mode):\n",
        "  return trax.models.TransformerLM(   # You can try trax_models.ReformerLM too.\n",
        "    d_model=1024, d_ff=4096, n_layers=12, vocab_size=256, mode=mode)\n",
        "\n",
        "train_model = transformer_lm('train')\n",
        "\n",
        "# Initialize model by hand\n",
        "signature = trax.shapes.signature((inputs, targets, mask))\n",
        "random_key = trax.math.random.get_prng(0)\n",
        "train_model.init(signature)\n",
        "\n",
        "# Take one prediction just to see\n",
        "pred, targets, mask = train_model((inputs, targets, mask), rng=random_key)\n",
        "print(pred.shape, targets.shape, mask.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "height": 1000
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 128609,
          "status": "ok",
          "timestamp": 1578614030616,
          "user": {
            "displayName": "Lukasz Kaiser",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC8pChl87HbK_eOtVhtNPwUVx8btvfyYzH9UHn3=s64",
            "userId": "13267693649565518272"
          },
          "user_tz": 480
        },
        "id": "kSauPt0NUl_o",
        "outputId": "8c82ac7b-b3b7-411f-8d6b-aa385daaa7f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Step     10: Ran 10 train steps in 65.90 secs\n",
            "Step     10: Evaluation\n",
            "Step     10: train                   accuracy |  0.00000000\n",
            "Step     10: train                       loss |  6.12401772\n",
            "Step     10: train         neg_log_perplexity | -6.12401772\n",
            "Step     10: train weights_per_batch_per_core |  4.00000000\n",
            "Step     10: eval                    accuracy |  0.00694444\n",
            "Step     10: eval                        loss |  6.51908636\n",
            "Step     10: eval          neg_log_perplexity | -6.51908636\n",
            "Step     10: eval  weights_per_batch_per_core |  6.50000000\n",
            "Step     10: Finished evaluation\n",
            "\n",
            "Step    110: Ran 100 train steps in 5.55 secs\n",
            "Step    110: Evaluation\n",
            "Step    110: train                   accuracy |  0.04861111\n",
            "Step    110: train                       loss |  3.55456662\n",
            "Step    110: train         neg_log_perplexity | -3.55456662\n",
            "Step    110: train weights_per_batch_per_core |  9.00000000\n",
            "Step    110: eval                    accuracy |  0.02083333\n",
            "Step    110: eval                        loss |  3.58572221\n",
            "Step    110: eval          neg_log_perplexity | -3.58572221\n",
            "Step    110: eval  weights_per_batch_per_core |  9.00000000\n",
            "Step    110: Finished evaluation\n",
            "\n",
            "Step    210: Ran 100 train steps in 5.48 secs\n",
            "Step    210: Evaluation\n",
            "Step    210: train                   accuracy |  0.21701390\n",
            "Step    210: train                       loss |  2.76435089\n",
            "Step    210: train         neg_log_perplexity | -2.76435089\n",
            "Step    210: train weights_per_batch_per_core |  6.50000000\n",
            "Step    210: eval                    accuracy |  0.15625000\n",
            "Step    210: eval                        loss |  2.77072120\n",
            "Step    210: eval          neg_log_perplexity | -2.77072120\n",
            "Step    210: eval  weights_per_batch_per_core |  6.50000000\n",
            "Step    210: Finished evaluation\n",
            "\n",
            "Step    310: Ran 100 train steps in 5.50 secs\n",
            "Step    310: Evaluation\n",
            "Step    310: train                   accuracy |  0.43402779\n",
            "Step    310: train                       loss |  1.92522335\n",
            "Step    310: train         neg_log_perplexity | -1.92522335\n",
            "Step    310: train weights_per_batch_per_core |  6.50000000\n",
            "Step    310: eval                    accuracy |  0.47743055\n",
            "Step    310: eval                        loss |  1.69520509\n",
            "Step    310: eval          neg_log_perplexity | -1.69520509\n",
            "Step    310: eval  weights_per_batch_per_core |  6.50000000\n",
            "Step    310: Finished evaluation\n",
            "\n",
            "Step    410: Ran 100 train steps in 5.61 secs\n",
            "Step    410: Evaluation\n",
            "Step    410: train                   accuracy |  0.60763890\n",
            "Step    410: train                       loss |  1.38952565\n",
            "Step    410: train         neg_log_perplexity | -1.38952565\n",
            "Step    410: train weights_per_batch_per_core |  6.50000000\n",
            "Step    410: eval                    accuracy |  0.36805555\n",
            "Step    410: eval                        loss |  2.16996479\n",
            "Step    410: eval          neg_log_perplexity | -2.16996479\n",
            "Step    410: eval  weights_per_batch_per_core |  9.00000000\n",
            "Step    410: Finished evaluation\n",
            "\n",
            "Step    510: Ran 100 train steps in 5.52 secs\n",
            "Step    510: Evaluation\n",
            "Step    510: train                   accuracy |  0.84722221\n",
            "Step    510: train                       loss |  0.38497180\n",
            "Step    510: train         neg_log_perplexity | -0.38497180\n",
            "Step    510: train weights_per_batch_per_core |  9.00000000\n",
            "Step    510: eval                    accuracy |  0.81250000\n",
            "Step    510: eval                        loss |  0.43954566\n",
            "Step    510: eval          neg_log_perplexity | -0.43954566\n",
            "Step    510: eval  weights_per_batch_per_core |  9.00000000\n",
            "Step    510: Finished evaluation\n"
          ]
        }
      ],
      "source": [
        "# Train model with Trainer.\n",
        "output_dir = os.path.expanduser('~/train_dir/')\n",
        "!rm -f ~/train_dir/model.pkl  # Remove old model.j\n",
        "trainer = trax.supervised.Trainer(\n",
        "    model=transformer_lm,\n",
        "    loss_fn=trax.layers.CrossEntropyLossScalar,\n",
        "    optimizer=trax.optimizers.Adafactor,  # Change optimizer params here.\n",
        "    lr_schedule=trax.lr.MultifactorSchedule,  # Change lr schedule here.\n",
        "    inputs=copy_inputs,\n",
        "    output_dir=output_dir,\n",
        "    # metrics = {'loss': tl.CrossEntropyLossScalar},\n",
        "    has_weights=True)  # Because we have loss mask, API may change.\n",
        "train_steps=10\n",
        "eval_steps=2\n",
        "trainer.train_epoch(train_steps, eval_steps)\n",
        "# Do that more times with higher step counts.\n",
        "n_epochs  = 2\n",
        "train_steps = 50\n",
        "eval_steps = 2\n",
        "for _ in range(n_epochs):\n",
        "  trainer.train_epoch(train_steps, eval_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 2225,
          "status": "ok",
          "timestamp": 1578614032876,
          "user": {
            "displayName": "Lukasz Kaiser",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC8pChl87HbK_eOtVhtNPwUVx8btvfyYzH9UHn3=s64",
            "userId": "13267693649565518272"
          },
          "user_tz": 480
        },
        "id": "VBMrkP_kkQnX",
        "outputId": "fafb63e7-1857-4e4f-9073-25f25bf378de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded from /export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_deepmind_tpu_py3_lukaszkaiser.kernel.lukaszkaiser.723311151468.14b334fb3717c109/mount/alloc/scratch/train_dir/model.pkl at step 510\n"
          ]
        }
      ],
      "source": [
        "# Inference model\n",
        "predict_model = transformer_lm(mode='eval')\n",
        "predict_signature = trax.shapes.ShapeDtype((1,1), dtype=np.int32)\n",
        "predict_model.init(predict_signature)\n",
        "\n",
        "# Load from file (API for trainer_state may change, ugly for now)\n",
        "trainer_state = trax.supervised.trainer_lib.load_trainer_state(output_dir)\n",
        "predict_model.weights = trainer_state.opt_state.weights[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "height": 34
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 3366,
          "status": "ok",
          "timestamp": 1578614036261,
          "user": {
            "displayName": "Lukasz Kaiser",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC8pChl87HbK_eOtVhtNPwUVx8btvfyYzH9UHn3=s64",
            "userId": "13267693649565518272"
          },
          "user_tz": 480
        },
        "id": "_pQMXXnNqJQD",
        "outputId": "8e5fdc0f-db9e-4478-b5b2-e2babe6d1d4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 0, 4, 1, 2, 3]\n"
          ]
        }
      ],
      "source": [
        "# Run inference\n",
        "prefix = [0, 1, 2, 3, 4, 0]   # Change non-0 digits to see if it's copying\n",
        "cur_input = np.array(prefix, dtype=np.int32)\n",
        "cur_input = cur_input[None, :]\n",
        "result = [p for p in prefix]  # Copy\n",
        "for i in range(len(prefix) - 2):\n",
        "  logits = predict_model(cur_input, rng=random_key)\n",
        "  next_input = np.argmax(logits[:, -1, :], axis=-1)\n",
        "  cur_input = np.concatenate([cur_input, next_input[:, None]], axis=1)\n",
        "  result.append(int(next_input[0]))  # Append to the result\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "height": 68
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 14088,
          "status": "ok",
          "timestamp": 1578614134497,
          "user": {
            "displayName": "Lukasz Kaiser",
            "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mC8pChl87HbK_eOtVhtNPwUVx8btvfyYzH9UHn3=s64",
            "userId": "13267693649565518272"
          },
          "user_tz": 480
        },
        "id": "cqjYoxPEu8PG",
        "outputId": "eec29c3d-3198-4640-dbad-04ef7e72fd5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded from /export/hda3/borglet/remote_hdd_fs_dirs/0.colab_kernel_deepmind_tpu_py3_lukaszkaiser.kernel.lukaszkaiser.723311151468.14b334fb3717c109/mount/alloc/scratch/train_dir/model.pkl at step 510\n",
            "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
            "7.662297010421753\n"
          ]
        }
      ],
      "source": [
        "# Run fast inference (TransformerLM from scratch only)\n",
        "predict_model = transformer_lm(mode='predict')\n",
        "predict_signature = trax.shapes.ShapeDtype((1,1), dtype=np.int32)\n",
        "predict_model.init(predict_signature)\n",
        "\n",
        "# Load from file (API for trainer_state may change, ugly for now)\n",
        "trainer_state = trax.supervised.trainer_lib.load_trainer_state(output_dir)\n",
        "predict_model.weights = trainer_state.opt_state.weights[0]\n",
        "\n",
        "cur_input = np.array([0] * 128, dtype=np.int32)\n",
        "cur_input = cur_input[128, None]\n",
        "result = []\n",
        "for i in range(10):\n",
        "  logits = predict_model(cur_input, rng=random_key)\n",
        "  next_input = np.argmax(logits[:, 0, :], axis=-1)\n",
        "  cur_input = next_input[:, None]\n",
        "  result.append(int(next_input[0]))  # Append to the result\n",
        "print(result)\n",
        "\n",
        "import time\n",
        "cur_input = np.array([0] * 128, dtype=np.int32)\n",
        "cur_input = cur_input[128, None]\n",
        "result = []\n",
        "t = time.time()\n",
        "\n",
        "for i in range(10):\n",
        "  logits = predict_model(cur_input, rng=random_key)\n",
        "  next_input = np.argmax(logits[:, 0, :], axis=-1)\n",
        "  cur_input = next_input[:, None]\n",
        "  result.append(int(next_input[0]))  # Append to the result\n",
        "print(time.time() - t)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/dm_python:dm_notebook3_tpu",
        "kind": "private"
      },
      "name": "Trax Quick Intro",
      "provenance": [
        {
          "file_id": "1v1GvTkEFjMH_1c-bdS7JzNS70u9RUEHV",
          "timestamp": 1578614172992
        },
        {
          "file_id": "1SplqILjJr_ZqXcIUkNIk0tSbthfhYm07",
          "timestamp": 1572044421118
        },
        {
          "file_id": "trax/intro.ipynb",
          "timestamp": 1571858674399
        },
        {
          "file_id": "1sF8QbqJ19ZU6oy5z4GUTt4lgUCjqO6kt",
          "timestamp": 1569980697572
        },
        {
          "file_id": "1EH76AWQ_pvT4i8ZXfkv-SCV4MrmllEl5",
          "timestamp": 1563927451951
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
